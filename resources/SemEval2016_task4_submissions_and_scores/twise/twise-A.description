1. Team ID
twise

2. Team affiliation
University of Grenoble-Alpes

3. Contact information
Georgios Balikas
e-mail: georgios.balikas@imag.fr

4. Submission, i.e., ZIP file name
twise.zip

5. System specs

- 5.1 Core approach
The goal was to build an ensemble learning approach using two layers. In the first layer different classifiers are trained on the same data representation. In the second layer, a classifier is trained on the probabilistic outputs of the learners of the first layer. The submitted predictions are those of the second layer classifier. 

- 5.2 Supervised or unsupervised
A supervised learning method was applied.


- 5.3 Important/interesting/novel features used
We split the features in two types: 
    - (i) n-gram features that represent the raw content of tweets, and
    - (ii) lexical or hard-coded features that use semantic lexicons and features such as POS tags and punctuation counts which are used in the relevant bibliography and in past SemEval challenges.

For the group of features (i) instead of relying in a bag-of-words encoding of the n-grams n \in [1,4], we first used a hashing function to represent them in a vectorial space of pre-defined dimension. This improved the performance on the validation test and reduced the complexity of the problem. Also, for the same group of features, we used distributed representations specifically learnt for the sentiment analysis task [citation 2]. Hence, we had two different representations for the feaure set (i) and one way of representing feature set (ii). The concatenation of all three representations of features set (i) and (ii) were the inputs of SVMs and Logistic Regresions in the first layer of our ensemble. The SVM scores were transformed to probabilities using sigmoid (Platt's method) or isotonic (non-parametric approach) calibrations via 3-fold cross validation on the training data. 

In the algorithmic part, the classifiers of the first layer used different solvers and also different multi-class methods: for SVMs one-vs-rest and crammer-singer and for Logistic Regression one-vs-rest and multinomial. 

- 5.4 Important/interesting/novel tools used
In terms of tools we used standard implementations of classifiers but we investigated in depth the effect of the different multi-class strategies and the different solvers (liblinear, newton-cg etc.). We also found that due to the fact that the problem was unbalanced, weighting the classes benefited our approach.

- 5.5 Significant data pre/post-processing
We report two interesting pre-processing steps we used: the Hashing function that reduced the dimensionality and an a-power transformation on the outputs of the hashing function. Both helped to improve our performance.
We consider here as post-processing, the weighting of the dinstict classes to balance the problem and the application of the second layer classifier in the probabilistic outputs of a first layer. Both of them improved significantly (more that 2 points each) our MaF_1 scores in the local validation scheme we used (the validation and the devtest data provided by the organisers).  

- 5.6 Other data used (outside of the provided)
The semantic lexicons that have been used in the past SemEval challenges and the distributed representations of [citation 2]

- 5.7 Size of the training Twitter data used (some teams could only download part of the data)
Training: 5,500 tweets
Development: 1831 tweets
DevTest: 1791 tweets
In the submission, after tuning the parameters on both the dev and devtest, we retrained using the training data+devtest data (7,331 tweets)

- 5.8 Did you participate in SemEval-2013 task 2?
No.

- 5.9 Did you participate in SemEval-2014 task 9?
No.

- 5.10 Did you participate in SemEval-2015 task 10?
No.

6 References (if applicable)
    1. Sentiment analysis of short informal texts
        S. Kiritchenko, X. Zhu, SM. Mohammad
        JAIR 2014
    2. Learning Sentiment-Specific Word Embedding for Twitter Sentiment Classification.
        Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting Liu, Bing Qin. 
        Proceeding of the 52th Annual Meeting of the Association for Computational Linguistics (ACL 2014, full paper, Oral Presentation) 
    3. Webis: An Ensemble for Twitter Sentiment Detection. 
        Matthias Hagen, Martin Potthast, Michel BÃ¼chner, and Benno Stein.
        In Proceedings of SemEval 2015
    4. Supervised term weighting for automated text categorization
        F. Debole, F. Sebastiani 
        Text mining and its applications, 2004 - Springer
    5. Feature-Weighted Linear Stacking
        Joseph Sill, Gabor Takacs, Lester Mackey, and David Lin
        arXiv preprint arXiv:0911.0460, 2009
    6. Aggregating Local Image Descriptors into Compact Codes
        Jegou, H. and Perronnin, F. and Douze, M. and Sanchez, J. and Perez, P. and Schmid, C.
        IEEE Transactions on Pattern Analysis and Machine Intelligence


