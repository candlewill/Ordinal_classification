1. Team ID
PotTS

2. Team affiliation
University of Potsdam/Retresco GmbH

3. Contact information
Uladzimir Sidarenka <sidarenk@uni-pottsdam.de>
Kaiser-Friedrich Str., 124
14469 Potsdam
+49 176 957 63 296

4. Submission, i.e., ZIP file name
SemEval2016-task4-subtaskC.PotTS.res.official.txt (softconf paper 177)
SemEval2016-task4-subtaskE.PotTS.res.official.txt (softconf paper 178)

5. System specs

- 5.1 Core approach

  Character-level deep convolutional neural network.

- 5.2 Supervised or unsupervised

  supervised

- 5.3 Important/interesting/novel features used

  This submission relies on the same deep character-convolution neural
  network approach as used for subtask C, but aggregates the
  predictions using the official aggregator script provided by the
  organizers.

  Our method treats input messages as a plain sequence of characters
  and successively converts those characters into their vector
  representation (embeddings).  After this conversion is done, a set
  of convolutional filters is applied to the input embeddings
  (currently, we are using 4 filters of width three, 16 filters of
  width four, and 24 filters of width five).  We take max-over-time of
  these convolutions and pass this output to four non-linear layers
  with linear in-between transformations (currently, we are using one
  highway layer (Srivastava, 2015), one hyper-tangent layer, one layer
  with a sigmoid activation function, and a soft-max prediction layer
  as the final step).  We use RMS-prop (Tieleman, 2012) as a training
  function. The cost function that we are optimizing has been tailored
  to the peculiarities of this task and is formulated as follows:

  C = -log(pred[y]) + L3 * dist + L2 * sum([sum(p**2) for p in
  params]),

  where $pred[y]$ is the probability of predicting the gold label, $L3 *
  dist$ is the squared Euclidean distance between the made prediction
  and the true gold label, and the $L2 * sum([sum(p**2) for p in
  params])$ term denotes the L2 regularization of system's parameters.

  We do no preprocessing of the input messages except for removing stop
  words and lowercasing the input strings.  Additionally, we have
  enriched the training corpus by randomly sampling polar terms from two
  sentiment lexica -- the Sentiment Clues Lexicon (Wilson et al., 2005)
  and the NRC Hashtag Sentiment Lexicon (Mohammad, 2012) -- and
  assigning them gold labels according to their specified prior
  polarities.


- 5.4 Important/interesting/novel tools used

  * Theano (Python deep-learning library)
  * Lasagne (Python deep-learning library)

- 5.5 Significant data pre/post-processing

  no preprocessing (not even tokenization) is done except for
  lowercasing the input strings and removing stop words

- 5.6 Other data used (outside of the provided)

  * Sentiment Clues Lexicon (Wilson, 2005);
  * NRC Hashtag Affirmative Context Sentiment Lexicon (Kiritchenko, 2014)

- 5.7 Size of the training Twitter data used (some teams could only download part of the data)

  training dataset: 3,968 tweets;
  development dataset: 1,210 messages;

- 5.8 Did you participate in SemEval-2013 task 2?

  nope

- 5.9 Did you participate in SemEval-2014 task 9?

  nope

- 5.10 Did you participate in SemEval-2015 task 10?

  nope

6 References (if applicable)
@inproceedings{Wilson:05,
  author    = {Theresa Wilson and Janyce Wiebe and Paul Hoffmann},
  title     = {Recognizing Contextual Polarity in Phrase-Level
                  Sentiment Analysis},
  booktitle = {{HLT/EMNLP} 2005, Human Language Technology Conference
                  and Conference on Empirical Methods in Natural
                  Language Processing, Proceedings of the Conference,
                  6-8 October 2005, Vancouver, British Columbia,
                  Canada},
  year      = {2005},
  crossref  = {DBLP:conf/emnlp/2005},
  url       = {http://acl.ldc.upenn.edu/H/H05/H05-1044.pdf},
  timestamp = {Thu, 21 Dec 2006 10:35:02 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/naacl/WilsonWH05},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/jair/KiritchenkoZM14,
  author    = {Svetlana Kiritchenko and
               Xiaodan Zhu and
               Saif M. Mohammad},
  title     = {Sentiment Analysis of Short Informal Texts},
  journal   = {J. Artif. Intell. Res. {(JAIR)}},
  volume    = {50},
  pages     = {723--762},
  year      = {2014},
  url       = {http://dx.doi.org/10.1613/jair.4272},
  doi       = {10.1613/jair.4272},
  timestamp = {Mon, 08 Sep 2014 15:40:06 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/jair/KiritchenkoZM14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
